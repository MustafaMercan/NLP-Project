# GTU NLP Web Scraping Projesi - Teknik Rapor

## ğŸ“‹ Ä°Ã§indekiler

1. [Proje Genel BakÄ±ÅŸ](#1-proje-genel-bakÄ±ÅŸ)
2. [Mimari ve Sistem TasarÄ±mÄ±](#2-mimari-ve-sistem-tasarÄ±mÄ±)
3. [Teknoloji Stack ve KÃ¼tÃ¼phaneler](#3-teknoloji-stack-ve-kÃ¼tÃ¼phaneler)
4. [VeritabanÄ± Modelleri](#4-veritabanÄ±-modelleri)
5. [Servisler ve Ã‡alÄ±ÅŸma MantÄ±ÄŸÄ±](#5-servisler-ve-Ã§alÄ±ÅŸma-mantÄ±ÄŸÄ±)
6. [NLP Modelleri ve EÄŸitim SÃ¼reci](#6-nlp-modelleri-ve-eÄŸitim-sÃ¼reci)
7. [API Endpoint'leri](#7-api-endpointleri)
8. [Ä°ÅŸ AkÄ±ÅŸÄ± (Workflow)](#8-iÅŸ-akÄ±ÅŸÄ±-workflow)
9. [Ã–zellikler ve Yetenekler](#9-Ã¶zellikler-ve-yetenekler)
10. [Performans ve Optimizasyon](#10-performans-ve-optimizasyon)

---

## 1. Proje Genel BakÄ±ÅŸ

### 1.1 Proje AmacÄ±

GTU NLP Web Scraping Projesi, Gebze Teknik Ãœniversitesi web sitesinden veri Ã§ekme, yapÄ±landÄ±rma ve NLP (DoÄŸal Dil Ä°ÅŸleme) yÃ¶ntemleriyle sÄ±nÄ±flandÄ±rma yapan tam kapsamlÄ± bir web uygulamasÄ±dÄ±r.

### 1.2 Ana BileÅŸenler

Proje Ã¼Ã§ ana aÅŸamadan oluÅŸur:

1. **Web Scraping**: GTU web sitesinden veri Ã§ekme
2. **Ä°Ã§erik YapÄ±landÄ±rma**: Ã‡ekilen verileri yapÄ±landÄ±rÄ±lmÄ±ÅŸ formata dÃ¶nÃ¼ÅŸtÃ¼rme
3. **NLP SÄ±nÄ±flandÄ±rma**: Metinleri kategorilere ayÄ±rma ve sentiment analizi

### 1.3 Proje YapÄ±sÄ±

```
nlp-node/
â”œâ”€â”€ backend/              # Node.js backend uygulamasÄ±
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app.js       # Express uygulamasÄ±
â”‚   â”‚   â”œâ”€â”€ config/      # KonfigÃ¼rasyon dosyalarÄ±
â”‚   â”‚   â”œâ”€â”€ controllers/ # Route controller'larÄ±
â”‚   â”‚   â”œâ”€â”€ models/       # MongoDB modelleri
â”‚   â”‚   â”œâ”€â”€ routes/       # Express route'larÄ±
â”‚   â”‚   â”œâ”€â”€ services/    # Ä°ÅŸ mantÄ±ÄŸÄ± servisleri
â”‚   â”‚   â”œâ”€â”€ scripts/     # YardÄ±mcÄ± scriptler
â”‚   â”‚   â””â”€â”€ utils/       # YardÄ±mcÄ± fonksiyonlar
â”‚   â”œâ”€â”€ models_cache/    # EÄŸitilmiÅŸ NLP modelleri
â”‚   â””â”€â”€ package.json
â””â”€â”€ frontend/            # React frontend uygulamasÄ±
```

---

## 2. Mimari ve Sistem TasarÄ±mÄ±

### 2.1 Mimari Desen

Proje **MVC (Model-View-Controller)** mimarisini takip eder:

- **Model**: MongoDB ÅŸemalarÄ± (Mongoose ODM)
- **View**: React frontend (JSON API ile iletiÅŸim)
- **Controller**: Express route handler'larÄ±

### 2.2 KatmanlÄ± Mimari

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Frontend (React)            â”‚
â”‚    Dashboard, DataList, Charts      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTP/REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Controllers (Express)          â”‚
â”‚  dataController, nlpController,     â”‚
â”‚  scrapingController                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Services Layer              â”‚
â”‚  scraperService, nlpService,        â”‚
â”‚  contentExtractorService, etc.      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Models (Mongoose)               â”‚
â”‚  ScrapedData, StructuredContent,    â”‚
â”‚  ClassifiedData, SearchHistory       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         MongoDB Database             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.3 Veri AkÄ±ÅŸÄ±

1. **Scraping AÅŸamasÄ±**:
   ```
   URL Discovery â†’ Content Extraction â†’ Structured Content â†’ Database
   ```

2. **NLP AÅŸamasÄ±**:
   ```
   Structured Content â†’ Language Detection â†’ Text Classification â†’ Classified Data
   ```

---

## 3. Teknoloji Stack ve KÃ¼tÃ¼phaneler

### 3.1 Backend Teknolojileri

#### Core Framework
- **Node.js** (v18+): JavaScript runtime environment
- **Express.js** (v4.18.2): Web framework
- **MongoDB**: NoSQL veritabanÄ±
- **Mongoose** (v7.5.0): ODM (Object Data Modeling)

#### Web Scraping
- **Cheerio** (v1.0.0-rc.12): Server-side HTML parsing (jQuery benzeri)
- **Puppeteer** (v21.0.0): Headless browser (dinamik iÃ§erik iÃ§in)
- **Axios** (v1.5.0): HTTP client

#### NLP (Natural Language Processing)
- **Natural.js** (v6.5.0): 
  - Naive Bayes Classifier
  - TF-IDF (Term Frequency-Inverse Document Frequency)
  - Word Tokenizer
  - Stop Words
- **Franc** (v6.2.0): Dil tespiti kÃ¼tÃ¼phanesi (400+ dil desteÄŸi)

#### GÃ¼venlik ve Middleware
- **Helmet** (v7.0.0): HTTP header gÃ¼venliÄŸi
- **CORS** (v2.8.5): Cross-Origin Resource Sharing
- **express-rate-limit** (v6.10.0): Rate limiting
- **Morgan** (v1.10.0): HTTP request logger

#### DiÄŸer
- **dotenv** (v16.3.1): Environment variables
- **validator** (v13.11.0): Input validation

### 3.2 Frontend Teknolojileri

- **React**: UI framework
- **Vite**: Build tool ve dev server
- **Material-UI (MUI)**: UI component library
- **Recharts**: Chart/graph library
- **React Router**: Routing
- **Axios**: API client

---

## 4. VeritabanÄ± Modelleri

### 4.1 ScrapedData Model

Ham scraped verileri saklar.

**Åema:**
```javascript
{
  title: String (required, trimmed),
  content: String (default: ''),
  url: String (required, unique, trimmed),
  source: String (required, trimmed),
  scrapedAt: Date (default: Date.now),
  metadata: {
    author: String,
    publishDate: Date,
    tags: [String],
    imageUrl: String
  },
  isClassified: Boolean (default: false),
  searchQuery: String (required),
  createdAt: Date,
  updatedAt: Date
}
```

**Indexes:**
- `url`: 1` (unique lookup iÃ§in)
- `scrapedAt: -1` (tarih sÄ±ralamasÄ± iÃ§in)
- `isClassified: 1` (filtreleme iÃ§in)
- `searchQuery: 1` (arama geÃ§miÅŸi iÃ§in)

### 4.2 StructuredContent Model

YapÄ±landÄ±rÄ±lmÄ±ÅŸ iÃ§eriÄŸi saklar. ScrapedData ile 1:1 iliÅŸki.

**Åema:**
```javascript
{
  scrapedDataId: ObjectId (ref: ScrapedData, required, unique),
  headers: [{
    level: Number (1-6, h1-h6),
    text: String,
    order: Number
  }],
  paragraphs: [{
    text: String,
    order: Number
  }],
  links: [{
    text: String,
    url: String,
    isInternal: Boolean,
    order: Number
  }],
  images: [{
    alt: String,
    src: String,
    order: Number
  }],
  lists: [{
    type: String (enum: ['ordered', 'unordered']),
    items: [String],
    order: Number
  }],
  cleanText: String,        // NLP iÃ§in temizlenmiÅŸ metin
  wordCount: Number,       // Kelime sayÄ±sÄ±
  language: String (default: 'tr'),
  extractedAt: Date (default: Date.now),
  createdAt: Date,
  updatedAt: Date
}
```

**Indexes:**
- `scrapedDataId: 1` (lookup iÃ§in)
- Text index: `headers.text`, `paragraphs.text`, `cleanText` (full-text search iÃ§in)

### 4.3 ClassifiedData Model

NLP sÄ±nÄ±flandÄ±rma sonuÃ§larÄ±nÄ± saklar. ScrapedData ile 1:1 iliÅŸki.

**Åema:**
```javascript
{
  scrapedDataId: ObjectId (ref: ScrapedData, required, unique),
  category: String (required, enum: [
    'Haberler',
    'Akademik Duyurular',
    'Etkinlikler',
    'AraÅŸtÄ±rma Projeleri',
    'Ã–ÄŸrenci DuyurularÄ±',
    'DiÄŸer'
  ]),
  confidence: Number (required, min: 0, max: 1),
  sentiment: String (enum: ['positive', 'neutral', 'negative'], default: 'neutral'),
  sentimentScore: Number (min: -1, max: 1, default: 0),
  keywords: [{
    word: String,
    weight: Number
  }],
  entities: [{
    type: String,
    value: String
  }],
  summary: String,
  nlpMetadata: {
    tokenCount: Number,
    processedAt: Date,
    model: String
  },
  createdAt: Date,
  updatedAt: Date
}
```

**Indexes:**
- `category: 1` (kategori filtreleme iÃ§in)
- `sentiment: 1` (sentiment filtreleme iÃ§in)
- `confidence: -1` (gÃ¼ven skoruna gÃ¶re sÄ±ralama iÃ§in)
- `scrapedDataId: 1` (lookup iÃ§in)

### 4.4 SearchHistory Model

Arama ve scraping iÅŸlemlerinin geÃ§miÅŸini saklar.

**Åema:**
```javascript
{
  query: String (required),
  status: String (enum: ['in_progress', 'completed', 'failed']),
  resultsCount: Number,
  scrapedDataIds: [ObjectId],
  error: String,
  createdAt: Date,
  completedAt: Date
}
```

### 4.5 Model Ä°liÅŸkileri

```
ScrapedData (1) â”€â”€â”€â”€ (1) StructuredContent
    â”‚
    â”‚ (1)
    â”‚
    â””â”€â”€â”€ (1) ClassifiedData

SearchHistory (1) â”€â”€â”€â”€ (N) ScrapedData
```

---

## 5. Servisler ve Ã‡alÄ±ÅŸma MantÄ±ÄŸÄ±

### 5.1 ScraperService

**AmaÃ§**: Web sayfalarÄ±ndan iÃ§erik Ã§ekme

**Ana Fonksiyonlar:**
- `searchWeb(query, maxResults)`: Web aramasÄ± yapar (DuckDuckGo/Google)
- `scrapeUrl(url, retries)`: Belirli bir URL'den iÃ§erik Ã§eker
- `processSearchResults(results)`: Arama sonuÃ§larÄ±nÄ± iÅŸler

**Ã‡alÄ±ÅŸma MantÄ±ÄŸÄ±:**
1. Cheerio ile statik iÃ§erik Ã§ekmeyi dener (daha hÄ±zlÄ±)
2. BaÅŸarÄ±sÄ±z olursa Puppeteer ile dinamik iÃ§erik Ã§eker
3. Retry mekanizmasÄ± (varsayÄ±lan 2 retry)
4. Exponential backoff ile bekleme
5. Timeout: 20 saniye

**Ã–zellikler:**
- User-Agent spoofing
- HTTP keep-alive connections
- Error handling ve logging

### 5.2 ContentExtractorService

**AmaÃ§**: HTML iÃ§eriÄŸini yapÄ±landÄ±rÄ±lmÄ±ÅŸ formata dÃ¶nÃ¼ÅŸtÃ¼rme

**Ana Fonksiyonlar:**
- `extractStructuredContent(url)`: YapÄ±landÄ±rÄ±lmÄ±ÅŸ iÃ§erik Ã§Ä±karÄ±r
- `extractStructuredContentWithPuppeteer(url)`: Puppeteer ile iÃ§erik Ã§Ä±karÄ±r

**Ã‡Ä±karÄ±lan BileÅŸenler:**
1. **Headers** (h1-h6): Seviye, metin, sÄ±ra
2. **Paragraphs**: Paragraf metinleri
3. **Links**: Link metni, URL, internal/external kontrolÃ¼
4. **Images**: Alt text, src URL
5. **Lists**: SÄ±ralÄ±/sÄ±rasÄ±z listeler

**Temizleme Ä°ÅŸlemleri:**
- Script, style, noscript, iframe elementleri kaldÄ±rÄ±lÄ±r
- Gereksiz boÅŸluklar temizlenir
- `cleanText`: TÃ¼m metinler birleÅŸtirilir (NLP iÃ§in)
- Kelime sayÄ±sÄ± hesaplanÄ±r
- Minimum 10 kelime kontrolÃ¼

**Dil Tespiti:**
- `languageDetectionService.detectLanguage()` ile dil tespiti yapÄ±lÄ±r
- TÃ¼rkÃ§e veya Ä°ngilizce olarak iÅŸaretlenir

### 5.3 LanguageDetectionService

**AmaÃ§**: Metin dilini tespit etme (TÃ¼rkÃ§e/Ä°ngilizce)

**KÃ¼tÃ¼phane**: `franc` (400+ dil desteÄŸi)

**Algoritma:**
1. Metin uzunluÄŸu < 10 karakter: Basit TÃ¼rkÃ§e karakter kontrolÃ¼
2. Metin uzunluÄŸu >= 10 karakter: `franc` kÃ¼tÃ¼phanesi ile tespit
3. ISO 639-3 kodlarÄ± â†’ Proje kodlarÄ±na mapping:
   - `tur` â†’ `tr`
   - `eng` â†’ `en`
   - DiÄŸerleri â†’ TÃ¼rkÃ§e karakter varsa `tr`, yoksa `en`

**Fonksiyonlar:**
- `detectLanguage(text)`: Dil tespiti
- `normalizeTextByLanguage(text, language)`: Metin normalizasyonu

### 5.4 NLPService

**AmaÃ§**: Metin sÄ±nÄ±flandÄ±rma ve NLP iÅŸlemleri

**Ana Fonksiyonlar:**
- `trainModels()`: NLP modellerini eÄŸitir
- `classifyText(scrapedDataId)`: Tek bir metni sÄ±nÄ±flandÄ±rÄ±r
- `classifyBatch(limit)`: Toplu sÄ±nÄ±flandÄ±rma
- `loadTrainedModels()`: KaydedilmiÅŸ modelleri yÃ¼kler

**SÄ±nÄ±flandÄ±rma YaklaÅŸÄ±mÄ±: Hybrid (Rule-based + ML)**

#### 5.4.1 Rule-based Classification

**URL Pattern Matching:**
- `/haber`, `/news`, `/haberler` â†’ Haberler (confidence: 0.9)
- `/duyuru`, `/announcement` â†’ Akademik Duyurular (confidence: 0.85)
- `/etkinlik`, `/event` â†’ Etkinlikler (confidence: 0.9)

**Keyword Matching:**
Her kategori iÃ§in Ã¶zel keyword listeleri:
- **Haberler**: haber, news, gÃ¼ncel, baÅŸarÄ±, Ã¶dÃ¼l, vb.
- **Akademik Duyurular**: akademik, duyuru, ilan, baÅŸvuru, vb.
- **Etkinlikler**: etkinlik, event, seminer, konferans, vb.
- **AraÅŸtÄ±rma Projeleri**: araÅŸtÄ±rma, research, proje, ar-ge, vb.
- **Ã–ÄŸrenci DuyurularÄ±**: Ã¶ÄŸrenci, student, burs, staj, vb.

Skor hesaplama: Her keyword iÃ§in eÅŸleÅŸme sayÄ±sÄ± toplanÄ±r, confidence 0.6-0.9 arasÄ± hesaplanÄ±r.

#### 5.4.2 ML Classification (Naive Bayes)

**Model TÃ¼rleri:**
- TÃ¼rkÃ§e Classifier: `turkishClassifier`
- Ä°ngilizce Classifier: `englishClassifier`

**EÄŸitim SÃ¼reci:**
1. VeritabanÄ±ndan `StructuredContent` verileri Ã§ekilir
2. Dil tespiti yapÄ±lÄ±r (TÃ¼rkÃ§e/Ä°ngilizce ayrÄ±lÄ±r)
3. Rule-based ile etiketleme (confidence > 0.7)
4. Tokenization ve stop words kaldÄ±rma
5. Naive Bayes classifier'a ekleme
6. Model eÄŸitimi
7. Model dosyaya kaydedilir (`models_cache/`)

**Model Persistence:**
- Kaydetme: `models_cache/turkish-classifier.json`
- Kaydetme: `models_cache/english-classifier.json`
- YÃ¼kleme: Uygulama baÅŸlatÄ±ldÄ±ÄŸÄ±nda otomatik

**Tokenization:**
- `natural.WordTokenizer` kullanÄ±lÄ±r
- Stop words kaldÄ±rÄ±lÄ±r (TÃ¼rkÃ§e/Ä°ngilizce ayrÄ± listeler)
- Minimum 2 karakter, sayÄ±lar filtrelenir

#### 5.4.3 Hybrid Classification Logic

SÄ±nÄ±flandÄ±rma Ã¶ncelik sÄ±rasÄ±:
1. Rule-based (confidence >= 0.8) â†’ Kullan
2. ML model (confidence >= 0.6) â†’ Kullan
3. Rule-based (dÃ¼ÅŸÃ¼k confidence) â†’ Kullan
4. ML model (dÃ¼ÅŸÃ¼k confidence) â†’ Kullan
5. VarsayÄ±lan: "DiÄŸer" (confidence: 0.5)

#### 5.4.4 Sentiment Analysis

**Algoritma**: Basit keyword-based sentiment analysis

**Pozitif Kelimeler:**
- TÃ¼rkÃ§e: baÅŸarÄ±, Ã¶dÃ¼l, tebrik, kutlama, baÅŸarÄ±lÄ±, gÃ¼zel, iyi, harika
- Ä°ngilizce: success, award, congratulations, celebration, successful, good, great, excellent

**Negatif Kelimeler:**
- TÃ¼rkÃ§e: sorun, problem, hata, baÅŸarÄ±sÄ±z, kÃ¶tÃ¼, Ã¼zÃ¼cÃ¼
- Ä°ngilizce: problem, issue, error, failed, bad, sad

**Skor Hesaplama:**
```
score = (positiveCount - negativeCount) / total
```

**SÄ±nÄ±flandÄ±rma:**
- score > 0.2 â†’ positive
- score < -0.2 â†’ negative
- DiÄŸerleri â†’ neutral

#### 5.4.5 Keyword Extraction

**YÃ¶ntem**: TF-IDF (Term Frequency-Inverse Document Frequency)

**SÃ¼reÃ§:**
1. Tokenization ve stop words kaldÄ±rma
2. TF-IDF hesaplama (`natural.TfIdf`)
3. En yÃ¼ksek aÄŸÄ±rlÄ±klÄ± 10 kelime seÃ§ilir

### 5.5 DomainService

**AmaÃ§**: Domain analizi ve sayfa keÅŸfi

**Ana Fonksiyonlar:**
- `extractGTUDomains()`: GTU domain'lerini Ã§Ä±karÄ±r
- `extractDomainsFromUrl(url)`: URL'den domain Ã§Ä±karÄ±r
- `discoverGTUPages(baseUrl, maxPages)`: Recursive sayfa keÅŸfi

**Ã–zellikler:**
- Domain ve subdomain analizi
- Recursive link takibi
- Duplicate URL kontrolÃ¼
- Depth limit kontrolÃ¼

### 5.6 SearchService

**AmaÃ§**: Web aramasÄ± iÅŸlemleri

**Ana Fonksiyonlar:**
- `wideSearchGTU(maxResultsPerQuery, maxResults)`: GeniÅŸ arama
- `searchByCategory(category, maxResults)`: Kategori bazlÄ± arama
- `searchMultipleQueries(queries, maxResultsPerQuery)`: Ã‡oklu sorgu aramasÄ±

---

## 6. NLP Modelleri ve EÄŸitim SÃ¼reci

### 6.1 Model TÃ¼rleri

#### 6.1.1 Naive Bayes Classifier

**KÃ¼tÃ¼phane**: Natural.js (`natural.BayesClassifier`)

**Ã–zellikler:**
- Probabilistic classifier
- Her dil iÃ§in ayrÄ± model (TÃ¼rkÃ§e/Ä°ngilizce)
- EÄŸitim verisi: Rule-based etiketlenmiÅŸ veriler

**Model DosyalarÄ±:**
- `backend/models_cache/turkish-classifier.json`
- `backend/models_cache/english-classifier.json`

### 6.2 EÄŸitim SÃ¼reci

#### 6.2.1 Veri HazÄ±rlama

1. **Veri Toplama:**
   ```javascript
   StructuredContent.aggregate([
     {
       $lookup: {
         from: 'scrapeddata',
         localField: 'scrapedDataId',
         foreignField: '_id',
         as: 'scrapedData'
       }
     },
     {
       $match: {
         cleanText: { $exists: true, $ne: null, $ne: '' },
         scrapedData: { $ne: [] }
       }
     }
   ])
   ```

2. **Filtreleme:**
   - `wordCount >= 10` veya `cleanText.length >= 50`
   - Null/undefined kontrolleri

3. **Dil AyrÄ±mÄ±:**
   - `detectLanguage(cleanText)` ile dil tespiti
   - TÃ¼rkÃ§e ve Ä°ngilizce veriler ayrÄ±lÄ±r

#### 6.2.2 Etiketleme

**YÃ¶ntem**: Rule-based etiketleme

1. Her veri iÃ§in `ruleBasedClassification()` Ã§aÄŸrÄ±lÄ±r
2. Confidence > 0.7 olanlar kabul edilir
3. Etiketlenen veriler eÄŸitim setine eklenir

#### 6.2.3 Model EÄŸitimi

**TÃ¼rkÃ§e Model:**
```javascript
turkishClassifier = new natural.BayesClassifier();

// Her eÄŸitim Ã¶rneÄŸi iÃ§in
turkishClassifier.addDocument(tokens.join(' '), category);

// EÄŸitim
turkishClassifier.train();
```

**Ä°ngilizce Model:**
AynÄ± sÃ¼reÃ§ Ä°ngilizce veriler iÃ§in tekrarlanÄ±r.

#### 6.2.4 Model Kaydetme

**YÃ¶ntem**: Natural.js `save()` metodu

```javascript
classifier.save(modelPath, (err) => {
  if (err) {
    log.error(`Model kaydetme hatasÄ±: ${err.message}`);
  } else {
    log.info(`Model dosyaya kaydedildi: ${modelPath}`);
  }
});
```

**Dosya FormatÄ±**: JSON

#### 6.2.5 Model YÃ¼kleme

**Zaman**: Uygulama baÅŸlatÄ±ldÄ±ÄŸÄ±nda (`app.js`)

```javascript
import { loadTrainedModels } from './services/nlpService.js';
loadTrainedModels();
```

**YÃ¶ntem**: Natural.js `load()` metodu

```javascript
natural.BayesClassifier.load(modelPath, null, (err, classifier) => {
  if (err) {
    log.error(`Model yÃ¼kleme hatasÄ±: ${err.message}`);
  } else {
    turkishClassifier = classifier;
  }
});
```

### 6.3 Model KullanÄ±mÄ±

#### 6.3.1 SÄ±nÄ±flandÄ±rma

```javascript
const tokens = tokenizeAndRemoveStopWords(cleanText, language);
const classification = classifier.classify(tokens.join(' '));
const confidence = classifier.getClassifications(tokens.join(' '));
```

#### 6.3.2 Confidence Hesaplama

En yÃ¼ksek probability deÄŸeri confidence olarak kullanÄ±lÄ±r.

### 6.4 Model PerformansÄ±

**EÄŸitim Verisi:**
- Rule-based etiketlenmiÅŸ veriler
- Minimum confidence: 0.7
- Minimum kelime sayÄ±sÄ±: 10

**Model Kalitesi:**
- Hybrid yaklaÅŸÄ±m ile yÃ¼ksek doÄŸruluk
- Rule-based yÃ¼ksek confidence durumlarÄ±nda Ã¶ncelikli
- ML model dÃ¼ÅŸÃ¼k confidence durumlarÄ±nda devreye girer

---

## 7. API Endpoint'leri

### 7.1 Data Endpoints (`/api/data`)

| Method | Endpoint | AÃ§Ä±klama |
|--------|----------|----------|
| GET | `/api/data` | TÃ¼m verileri getir (pagination, filtreleme, sÄ±ralama) |
| GET | `/api/data/stats` | Ä°statistikleri getir |
| GET | `/api/data/:id` | Tek bir veriyi ID ile getir |

**Query Parametreleri:**
- `page`: Sayfa numarasÄ± (default: 1)
- `limit`: Sayfa baÅŸÄ±na kayÄ±t (default: 10)
- `category`: Kategori filtresi
- `search`: Arama sorgusu
- `sortBy`: SÄ±ralama alanÄ± (`title`, `category`, `confidence`, `scrapedAt`)
- `sortOrder`: SÄ±ralama yÃ¶nÃ¼ (`asc`, `desc`)

### 7.2 Scraping Endpoints (`/api/scrape`)

| Method | Endpoint | AÃ§Ä±klama |
|--------|----------|----------|
| GET | `/api/scrape/search` | Web aramasÄ± yap ve URL'leri bul |
| GET | `/api/scrape/content/test` | Ä°Ã§erik Ã§ekme testi (console output) |
| POST | `/api/scrape/content` | URL'lerden iÃ§erik Ã§ek ve DB'ye kaydet |
| GET | `/api/scrape/domains` | Domain ve subdomain analizi |
| GET | `/api/scrape/discover` | GTU sayfalarÄ±nÄ± recursive keÅŸfet |
| POST | `/api/scrape` | Genel scraping baÅŸlat |
| GET | `/api/scrape/status/:id` | Scraping durumunu getir |
| GET | `/api/scrape/results/:id` | Scraping sonuÃ§larÄ±nÄ± getir |

### 7.3 NLP Endpoints (`/api/nlp`)

| Method | Endpoint | AÃ§Ä±klama |
|--------|----------|----------|
| POST | `/api/nlp/train` | NLP modellerini eÄŸit |
| POST | `/api/nlp/classify` | Tek bir veriyi sÄ±nÄ±flandÄ±r |
| POST | `/api/nlp/classify/batch` | Toplu sÄ±nÄ±flandÄ±rma |
| GET | `/api/nlp/categories` | Kategorileri getir |
| GET | `/api/nlp/stats` | NLP istatistiklerini getir |
| GET | `/api/nlp/debug/db` | VeritabanÄ± durumunu kontrol et |

---

## 8. Ä°ÅŸ AkÄ±ÅŸÄ± (Workflow)

### 8.1 Tam Ä°ÅŸ AkÄ±ÅŸÄ±

```
1. URL Discovery
   â”œâ”€â”€ Web aramasÄ± (DuckDuckGo/Google)
   â”œâ”€â”€ Domain keÅŸfi
   â””â”€â”€ Recursive sayfa keÅŸfi
        â”‚
        â–¼
2. URL Kaydetme
   â””â”€â”€ ScrapedData modeline kaydet
        â”‚
        â–¼
3. Ä°Ã§erik Ã‡ekme
   â”œâ”€â”€ Cheerio ile statik iÃ§erik
   â”œâ”€â”€ Puppeteer ile dinamik iÃ§erik (fallback)
   â””â”€â”€ Retry mekanizmasÄ±
        â”‚
        â–¼
4. Ä°Ã§erik YapÄ±landÄ±rma
   â”œâ”€â”€ Headers Ã§Ä±karma
   â”œâ”€â”€ Paragraphs Ã§Ä±karma
   â”œâ”€â”€ Links Ã§Ä±karma
   â”œâ”€â”€ Images Ã§Ä±karma
   â”œâ”€â”€ Lists Ã§Ä±karma
   â”œâ”€â”€ Clean text oluÅŸturma
   â””â”€â”€ StructuredContent modeline kaydet
        â”‚
        â–¼
5. Dil Tespiti
   â””â”€â”€ Franc kÃ¼tÃ¼phanesi ile dil tespiti
        â”‚
        â–¼
6. NLP SÄ±nÄ±flandÄ±rma
   â”œâ”€â”€ Rule-based classification
   â”œâ”€â”€ ML classification (Naive Bayes)
   â”œâ”€â”€ Hybrid sonuÃ§ birleÅŸtirme
   â”œâ”€â”€ Sentiment analysis
   â”œâ”€â”€ Keyword extraction (TF-IDF)
   â””â”€â”€ ClassifiedData modeline kaydet
```

### 8.2 Ã–rnek Senaryo

**1. Veri Ã‡ekme:**
```bash
# GTU sayfalarÄ±nÄ± keÅŸfet
curl "http://localhost:5004/api/scrape/discover?maxPages=50"

# Ä°Ã§erik Ã§ek
curl -X POST "http://localhost:5004/api/scrape/content?limit=100"
```

**2. NLP Ä°ÅŸlemleri:**
```bash
# Model eÄŸit
curl -X POST "http://localhost:5004/api/nlp/train"

# SÄ±nÄ±flandÄ±r
curl -X POST "http://localhost:5004/api/nlp/classify/batch?limit=500"
```

**3. Veri GÃ¶rÃ¼ntÃ¼leme:**
- Frontend: `http://localhost:5173`
- Dashboard'da istatistikler
- Veriler sayfasÄ±nda filtreleme ve sÄ±ralama

---

## 9. Ã–zellikler ve Yetenekler

### 9.1 Web Scraping Ã–zellikleri

âœ… **DuckDuckGo ve Google arama desteÄŸi**
- Rate limiting
- Error handling

âœ… **Cheerio ve Puppeteer desteÄŸi**
- Statik iÃ§erik: Cheerio (hÄ±zlÄ±)
- Dinamik iÃ§erik: Puppeteer (fallback)

âœ… **Recursive sayfa keÅŸfi**
- Depth limit kontrolÃ¼
- Duplicate URL kontrolÃ¼

âœ… **Domain ve subdomain analizi**
- GTU domain'lerini otomatik tespit
- Subdomain keÅŸfi

âœ… **URL normalizasyonu**
- `/en/` formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rme
- BaÅŸarÄ±sÄ±z URL'lerin temizlenmesi

âœ… **Retry mekanizmasÄ±**
- Exponential backoff
- Configurable retry count

### 9.2 Ä°Ã§erik Ä°ÅŸleme Ã–zellikleri

âœ… **YapÄ±landÄ±rÄ±lmÄ±ÅŸ iÃ§erik Ã§Ä±karma**
- Headers (h1-h6)
- Paragraphs
- Links (internal/external)
- Images (alt text, src)
- Lists (ordered/unordered)

âœ… **Temiz metin oluÅŸturma**
- Script/style elementleri kaldÄ±rma
- BoÅŸluk normalizasyonu
- NLP iÃ§in optimize edilmiÅŸ format

âœ… **Dil tespiti**
- Franc kÃ¼tÃ¼phanesi (400+ dil)
- TÃ¼rkÃ§e/Ä°ngilizce odaklÄ±
- Fallback mekanizmasÄ±

âœ… **Ä°Ã§erik filtreleme**
- Minimum kelime sayÄ±sÄ± (10)
- PDF, resim, JS/CSS dosyalarÄ± filtrelenir

### 9.3 NLP SÄ±nÄ±flandÄ±rma Ã–zellikleri

âœ… **Hybrid Classification**
- Rule-based (yÃ¼ksek confidence)
- ML model (Naive Bayes)
- Otomatik sonuÃ§ birleÅŸtirme

âœ… **Dil bazlÄ± modeller**
- TÃ¼rkÃ§e classifier
- Ä°ngilizce classifier
- Otomatik dil tespiti

âœ… **Sentiment Analysis**
- Positive/negative/neutral
- Keyword-based scoring
- Dil bazlÄ± kelime listeleri

âœ… **Keyword Extraction**
- TF-IDF algoritmasÄ±
- Top 10 keywords
- AÄŸÄ±rlÄ±k skorlarÄ±

âœ… **Model Persistence**
- Disk'e kaydetme
- Otomatik yÃ¼kleme
- JSON formatÄ±nda saklama

âœ… **Toplu sÄ±nÄ±flandÄ±rma**
- Batch processing
- Progress tracking
- Error handling

### 9.4 Kategoriler

1. **Haberler**: Haber, gÃ¼ncel geliÅŸmeler, baÅŸarÄ±lar
2. **Akademik Duyurular**: Akademik ilanlar, duyurular
3. **Etkinlikler**: Seminer, konferans, workshop
4. **AraÅŸtÄ±rma Projeleri**: AraÅŸtÄ±rma, proje, AR-GE
5. **Ã–ÄŸrenci DuyurularÄ±**: Ã–ÄŸrenci ilanlarÄ±, burs, staj
6. **DiÄŸer**: DiÄŸer iÃ§erikler

### 9.5 Frontend Ã–zellikleri

âœ… **Dashboard**
- 8 KPI kartÄ±
- Pie charts (kategori, sentiment)
- Bar charts (detaylÄ± istatistikler)
- Son eklenen veriler

âœ… **Veri Listesi**
- Filtreleme (kategori, arama)
- SÄ±ralama (baÅŸlÄ±k, kategori, gÃ¼ven)
- Pagination
- Detay modal

âœ… **Responsive TasarÄ±m**
- Mobile-friendly
- Dark theme

---

## 10. Performans ve Optimizasyon

### 10.1 VeritabanÄ± Optimizasyonu

**Indexes:**
- URL lookup iÃ§in unique index
- Tarih sÄ±ralamasÄ± iÃ§in descending index
- Kategori/sentiment filtreleme iÃ§in index
- Full-text search iÃ§in text index

**Query Optimizasyonu:**
- Lean queries (sadece gerekli alanlar)
- Pagination (limit/skip)
- Aggregate pipelines (efficient joins)

### 10.2 Scraping Optimizasyonu

**Connection Pooling:**
- HTTP keep-alive connections
- Reusable agents

**Rate Limiting:**
- 2 saniye bekleme arasÄ±
- Exponential backoff

**Error Handling:**
- Timeout: 20 saniye
- Retry mekanizmasÄ±
- Failed URL'lerin temizlenmesi

### 10.3 NLP Optimizasyonu

**Model Caching:**
- Disk'ten yÃ¼kleme (uygulama baÅŸlangÄ±cÄ±nda)
- Bellekte tutma (hÄ±zlÄ± eriÅŸim)

**Tokenization:**
- Stop words kaldÄ±rma (daha az token)
- Minimum token uzunluÄŸu (2 karakter)

**Batch Processing:**
- Toplu sÄ±nÄ±flandÄ±rma
- Progress tracking

### 10.4 API Optimizasyonu

**Rate Limiting:**
- 100 request / 15 dakika (IP bazlÄ±)
- Express-rate-limit middleware

**Caching:**
- Model caching (bellekte)
- Query result caching (gelecekte eklenebilir)

**Error Handling:**
- Try-catch bloklarÄ±
- Graceful error responses
- Logging

### 10.5 GÃ¼venlik

**Helmet:**
- HTTP header gÃ¼venliÄŸi
- XSS protection
- Content Security Policy

**CORS:**
- Configurable origins
- Development: tÃ¼m origin'lere izin
- Production: belirli origin'lere izin

**Input Validation:**
- Validator kÃ¼tÃ¼phanesi
- Mongoose schema validation

---

## SonuÃ§

GTU NLP Web Scraping Projesi, modern web teknolojileri ve NLP yÃ¶ntemleri kullanarak GTU web sitesinden veri Ã§ekme, yapÄ±landÄ±rma ve sÄ±nÄ±flandÄ±rma yapan kapsamlÄ± bir sistemdir. Hybrid classification yaklaÅŸÄ±mÄ± ile yÃ¼ksek doÄŸruluk oranÄ± saÄŸlanmÄ±ÅŸ, model persistence ile sÃ¼rekli Ã¶ÄŸrenme imkanÄ± sunulmuÅŸtur.

**GÃ¼Ã§lÃ¼ YÃ¶nler:**
- Hybrid classification (rule-based + ML)
- Dil bazlÄ± modeller (TÃ¼rkÃ§e/Ä°ngilizce)
- Model persistence
- Comprehensive error handling
- Scalable architecture

**Gelecek GeliÅŸtirmeler:**
- Daha fazla eÄŸitim verisi ile model iyileÅŸtirme
- Deep learning modelleri (BERT, etc.)
- Real-time classification
- Advanced sentiment analysis
- Entity recognition (NER)

---

**Rapor Tarihi**: 2024  
**Proje Versiyonu**: 1.0.0  
**HazÄ±rlayan**: AI Assistant

