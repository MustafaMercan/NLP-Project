# GTU NLP Web Scraping Projesi

Gebze Teknik Ãœniversitesi (GTU) web sitesinden veri Ã§ekme, yapÄ±landÄ±rma ve NLP yÃ¶ntemleriyle sÄ±nÄ±flandÄ±rma projesi.

## ğŸ“‹ Ä°Ã§indekiler

- [Genel BakÄ±ÅŸ](#genel-bakÄ±ÅŸ)
- [Teknoloji Stack](#teknoloji-stack)
- [Proje YapÄ±sÄ±](#proje-yapÄ±sÄ±)
- [Kurulum](#kurulum)
- [KullanÄ±m](#kullanÄ±m)
- [API Endpoint'leri](#api-endpointleri)
- [VeritabanÄ± Modelleri](#veritabanÄ±-modelleri)
- [Ã–zellikler](#Ã¶zellikler)
- [Frontend](#frontend)
- [GeliÅŸtirme NotlarÄ±](#geliÅŸtirme-notlarÄ±)

## ğŸ¯ Genel BakÄ±ÅŸ

Bu proje, GTU web sitesinden veri Ã§ekme, yapÄ±landÄ±rma ve NLP (DoÄŸal Dil Ä°ÅŸleme) yÃ¶ntemleriyle sÄ±nÄ±flandÄ±rma yapan tam kapsamlÄ± bir web uygulamasÄ±dÄ±r. Proje Ã¼Ã§ ana aÅŸamadan oluÅŸur:

1. **Web Scraping**: GTU web sitesinden veri Ã§ekme
2. **Ä°Ã§erik YapÄ±landÄ±rma**: Ã‡ekilen verileri yapÄ±landÄ±rÄ±lmÄ±ÅŸ formata dÃ¶nÃ¼ÅŸtÃ¼rme
3. **NLP SÄ±nÄ±flandÄ±rma**: Metinleri kategorilere ayÄ±rma ve sentiment analizi

## ğŸ›  Teknoloji Stack

### Backend
- **Node.js** - Runtime environment
- **Express.js** - Web framework
- **MongoDB** - VeritabanÄ±
- **Mongoose** - ODM (Object Data Modeling)
- **Cheerio** - HTML parsing
- **Puppeteer** - Headless browser (dinamik iÃ§erik)
- **Natural.js** - NLP kÃ¼tÃ¼phanesi (Naive Bayes, TF-IDF)
- **Axios** - HTTP client

### Frontend
- **React** - UI framework
- **Vite** - Build tool
- **Material-UI (MUI)** - UI component library
- **Recharts** - Chart/graph library
- **React Router** - Routing
- **Axios** - API client

## ğŸ“ Proje YapÄ±sÄ±

```
nlp-node/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app.js                 # Express uygulamasÄ±
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â””â”€â”€ database.js        # MongoDB baÄŸlantÄ±sÄ±
â”‚   â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”‚   â”œâ”€â”€ dataController.js  # Veri iÅŸlemleri
â”‚   â”‚   â”‚   â”œâ”€â”€ nlpController.js   # NLP iÅŸlemleri
â”‚   â”‚   â”‚   â””â”€â”€ scrapingController.js # Scraping iÅŸlemleri
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ ScrapedData.js     # Ham scraped veri modeli
â”‚   â”‚   â”‚   â”œâ”€â”€ StructuredContent.js # YapÄ±landÄ±rÄ±lmÄ±ÅŸ iÃ§erik modeli
â”‚   â”‚   â”‚   â”œâ”€â”€ ClassifiedData.js  # SÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ veri modeli
â”‚   â”‚   â”‚   â””â”€â”€ SearchHistory.js   # Arama geÃ§miÅŸi modeli
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ dataRoutes.js      # Veri endpoint'leri
â”‚   â”‚   â”‚   â”œâ”€â”€ nlpRoutes.js       # NLP endpoint'leri
â”‚   â”‚   â”‚   â””â”€â”€ scrapingRoutes.js  # Scraping endpoint'leri
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ scraperService.js  # Web scraping servisi
â”‚   â”‚   â”‚   â”œâ”€â”€ contentExtractorService.js # Ä°Ã§erik Ã§Ä±karma servisi
â”‚   â”‚   â”‚   â”œâ”€â”€ nlpService.js      # NLP servisi
â”‚   â”‚   â”‚   â”œâ”€â”€ languageDetectionService.js # Dil tespiti
â”‚   â”‚   â”‚   â”œâ”€â”€ domainService.js   # Domain analizi
â”‚   â”‚   â”‚   â””â”€â”€ searchService.js  # Arama servisi
â”‚   â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”‚   â””â”€â”€ migrateUrlsToEn.js # URL normalizasyon scripti
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ logger.js          # Logging utility
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ env.example
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ client.js          # Axios client
â”‚   â”‚   â”‚   â””â”€â”€ index.js           # API fonksiyonlarÄ±
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â””â”€â”€ Layout.jsx         # Ana layout component
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.jsx      # Dashboard sayfasÄ±
â”‚   â”‚   â”‚   â””â”€â”€ DataList.jsx      # Veri listesi sayfasÄ±
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ main.jsx
â”‚   â””â”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸš€ Kurulum

### Gereksinimler
- Node.js (v18 veya Ã¼zeri)
- MongoDB (yerel veya MongoDB Atlas)
- npm veya yarn

### Backend Kurulumu

```bash
cd backend
npm install
cp env.example .env
```

`.env` dosyasÄ±nÄ± dÃ¼zenleyin:
```env
PORT=5001
NODE_ENV=development
MONGODB_URI=mongodb://localhost:27017/gtu-nlp
FRONTEND_URL=http://localhost:5173
```

Backend'i baÅŸlatÄ±n:
```bash
npm run dev
```

### Frontend Kurulumu

```bash
cd frontend
npm install
```

Frontend'i baÅŸlatÄ±n:
```bash
npm run dev
```

## ğŸ“– KullanÄ±m

### 1. Web Scraping

#### URL KeÅŸfi (1. AÅŸama)
```bash
curl "http://localhost:5001/api/scrape/search?query=Gebze%20Teknik%20Ãœniversitesi&maxResults=10"
```

#### Ä°Ã§erik Ã‡ekme (2. AÅŸama)
```bash
# Test modu (console output)
curl "http://localhost:5001/api/scrape/content/test?limit=10"

# DB'ye kaydetme
curl -X POST "http://localhost:5001/api/scrape/content?limit=10"
```

#### GTU Sayfa KeÅŸfi
```bash
curl "http://localhost:5001/api/scrape/discover?baseUrl=https://www.gtu.edu.tr/en&maxPages=100"
```

### 2. NLP SÄ±nÄ±flandÄ±rma

#### Model EÄŸitimi
```bash
curl -X POST "http://localhost:5001/api/nlp/train"
```

#### Toplu SÄ±nÄ±flandÄ±rma
```bash
curl -X POST "http://localhost:5001/api/nlp/classify/batch?limit=500"
```

### 3. Veri GÃ¶rÃ¼ntÃ¼leme

Frontend'i aÃ§Ä±n: `http://localhost:5173`

- **Dashboard**: Genel istatistikler ve grafikler
- **Veriler**: SÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ verilerin listesi

## ğŸ”Œ API Endpoint'leri

### Veri Endpoint'leri (`/api/data`)

| Method | Endpoint | AÃ§Ä±klama |
|--------|----------|----------|
| GET | `/api/data` | TÃ¼m verileri getir (pagination, filtreleme, sÄ±ralama) |
| GET | `/api/data/stats` | Ä°statistikleri getir |
| GET | `/api/data/:id` | Tek bir veriyi ID ile getir |

**Query Parametreleri:**
- `page`: Sayfa numarasÄ± (default: 1)
- `limit`: Sayfa baÅŸÄ±na kayÄ±t (default: 10)
- `category`: Kategori filtresi
- `search`: Arama sorgusu
- `sortBy`: SÄ±ralama alanÄ± (`title`, `category`, `confidence`, `scrapedAt`)
- `sortOrder`: SÄ±ralama yÃ¶nÃ¼ (`asc`, `desc`)

### Scraping Endpoint'leri (`/api/scrape`)

| Method | Endpoint | AÃ§Ä±klama |
|--------|----------|----------|
| GET | `/api/scrape/search` | Web aramasÄ± yap ve URL'leri bul |
| GET | `/api/scrape/content/test` | Ä°Ã§erik Ã§ekme testi (console output) |
| POST | `/api/scrape/content` | URL'lerden iÃ§erik Ã§ek ve DB'ye kaydet |
| GET | `/api/scrape/domains` | Domain ve subdomain analizi |
| GET | `/api/scrape/discover` | GTU sayfalarÄ±nÄ± recursive keÅŸfet |
| POST | `/api/scrape` | Genel scraping baÅŸlat |
| GET | `/api/scrape/status/:id` | Scraping durumunu getir |
| GET | `/api/scrape/results/:id` | Scraping sonuÃ§larÄ±nÄ± getir |

**Query Parametreleri:**
- `query`: Arama sorgusu
- `maxResults`: Maksimum sonuÃ§ sayÄ±sÄ±
- `limit`: Ä°ÅŸlenecek kayÄ±t sayÄ±sÄ±
- `baseUrl`: BaÅŸlangÄ±Ã§ URL'i
- `maxPages`: Maksimum sayfa sayÄ±sÄ±

### NLP Endpoint'leri (`/api/nlp`)

| Method | Endpoint | AÃ§Ä±klama |
|--------|----------|----------|
| POST | `/api/nlp/train` | NLP modellerini eÄŸit |
| POST | `/api/nlp/classify` | Tek bir veriyi sÄ±nÄ±flandÄ±r |
| POST | `/api/nlp/classify/batch` | Toplu sÄ±nÄ±flandÄ±rma |
| GET | `/api/nlp/categories` | Kategorileri getir |
| GET | `/api/nlp/stats` | NLP istatistiklerini getir |
| GET | `/api/nlp/debug/db` | VeritabanÄ± durumunu kontrol et |

**Query Parametreleri:**
- `limit`: Toplu iÅŸlem iÃ§in kayÄ±t sayÄ±sÄ±

## ğŸ—„ VeritabanÄ± Modelleri

### ScrapedData
Ham scraped verileri saklar.
```javascript
{
  title: String,
  content: String,
  url: String (unique),
  source: String,
  scrapedAt: Date,
  metadata: {
    author: String,
    publishDate: Date,
    tags: [String],
    imageUrl: String
  },
  isClassified: Boolean,
  searchQuery: String
}
```

### StructuredContent
YapÄ±landÄ±rÄ±lmÄ±ÅŸ iÃ§eriÄŸi saklar.
```javascript
{
  scrapedDataId: ObjectId (ref: ScrapedData),
  headers: [{ level: Number, text: String, order: Number }],
  paragraphs: [{ text: String, order: Number }],
  links: [{ text: String, url: String, isInternal: Boolean, order: Number }],
  images: [{ alt: String, src: String, order: Number }],
  lists: [{ type: String, items: [String], order: Number }],
  cleanText: String,
  wordCount: Number,
  language: String
}
```

### ClassifiedData
SÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ verileri saklar.
```javascript
{
  scrapedDataId: ObjectId (ref: ScrapedData),
  category: String,
  confidence: Number (0-1),
  sentiment: String (positive/negative/neutral),
  sentimentScore: Number,
  keywords: [String],
  entities: [String],
  summary: String,
  nlpMetadata: Object
}
```

### SearchHistory
Arama geÃ§miÅŸini saklar.
```javascript
{
  query: String,
  foundUrls: [String],
  scrapedCount: Number,
  createdAt: Date
}
```

## âœ¨ Ã–zellikler

### Web Scraping
- âœ… DuckDuckGo ve Google arama desteÄŸi
- âœ… Cheerio ve Puppeteer ile statik/dinamik iÃ§erik Ã§ekme
- âœ… Recursive sayfa keÅŸfi
- âœ… Domain ve subdomain analizi
- âœ… URL normalizasyonu (`/en/` formatÄ±na)
- âœ… BaÅŸarÄ±sÄ±z URL'lerin otomatik temizlenmesi
- âœ… Retry mekanizmasÄ± (opsiyonel)

### Ä°Ã§erik Ä°ÅŸleme
- âœ… YapÄ±landÄ±rÄ±lmÄ±ÅŸ iÃ§erik Ã§Ä±karma (headers, paragraphs, links, images, lists)
- âœ… Temiz metin oluÅŸturma (NLP iÃ§in)
- âœ… Dil tespiti (TÃ¼rkÃ§e/Ä°ngilizce)
- âœ… Kelime sayÄ±sÄ± hesaplama
- âœ… Ä°Ã§erik filtreleme (PDF, resim, JS/CSS dosyalarÄ±)

### NLP SÄ±nÄ±flandÄ±rma
- âœ… Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ± (TÃ¼rkÃ§e ve Ä°ngilizce iÃ§in ayrÄ± modeller)
- âœ… Rule-based sÄ±nÄ±flandÄ±rma
- âœ… Sentiment analizi (positive/negative/neutral)
- âœ… Keyword extraction (TF-IDF)
- âœ… Model persistence (disk'e kaydetme/yÃ¼kleme)
- âœ… Toplu sÄ±nÄ±flandÄ±rma

### Kategoriler
- Haberler
- Akademik Duyurular
- Etkinlikler
- AraÅŸtÄ±rma Projeleri
- Ã–ÄŸrenci DuyurularÄ±
- DiÄŸer

### Frontend
- âœ… Dark theme dashboard
- âœ… Ä°statistik kartlarÄ± (8 KPI)
- âœ… Pie charts (kategori ve sentiment daÄŸÄ±lÄ±mÄ±)
- âœ… Bar chart (kategori bazÄ±nda detaylÄ± istatistikler)
- âœ… Veri listesi (filtreleme, arama, sÄ±ralama)
- âœ… Detay modal
- âœ… Responsive tasarÄ±m

## ğŸ¨ Frontend Ã–zellikleri

### Dashboard
- **8 KPI KartÄ±**: Toplam veri, sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ, sÄ±nÄ±flandÄ±rÄ±lmamÄ±ÅŸ, ortalama gÃ¼ven, toplam kelime, son 24 saat, max gÃ¼ven, sÄ±nÄ±flandÄ±rma oranÄ±
- **Grafikler**: Kategori daÄŸÄ±lÄ±mÄ± (pie), sentiment daÄŸÄ±lÄ±mÄ± (pie), kategori bazÄ±nda detaylÄ± istatistikler (bar)
- **Listeler**: Son eklenen veriler, en yÃ¼ksek gÃ¼ven skorlarÄ±, kategori ortalama gÃ¼ven skorlarÄ±

### Veriler SayfasÄ±
- **Filtreleme**: Kategori ve arama
- **SÄ±ralama**: BaÅŸlÄ±k, kategori, gÃ¼ven skoruna gÃ¶re
- **Pagination**: Sayfa sayfa gezinme
- **Detay Modal**: SatÄ±ra tÄ±klayarak detay gÃ¶rÃ¼ntÃ¼leme

## ğŸ”§ GeliÅŸtirme NotlarÄ±

### URL Normalizasyonu
TÃ¼m GTU URL'leri `/en/` formatÄ±na normalize edilir:
```bash
npm run migrate:urls        # Dry-run
npm run migrate:urls:execute # GerÃ§ek migration
```

### Model EÄŸitimi
Modeller `backend/models_cache/` dizinine kaydedilir ve sunucu baÅŸlatÄ±ldÄ±ÄŸÄ±nda otomatik yÃ¼klenir.

### CORS
Backend tÃ¼m origin'lere izin verir (development iÃ§in). Production'da `.env` dosyasÄ±nda `FRONTEND_URL` belirtilmelidir.

### Hata YÃ¶netimi
- BaÅŸarÄ±sÄ±z scraping iÅŸlemleri otomatik temizlenir
- Yetersiz iÃ§erik (< 10 kelime) filtrelenir
- Timeout ve connection hatalarÄ± yakalanÄ±r

## ğŸ“ Ã–rnek KullanÄ±m Senaryosu

1. **Veri Ã‡ekme**:
   ```bash
   # GTU sayfalarÄ±nÄ± keÅŸfet
   curl "http://localhost:5001/api/scrape/discover?maxPages=50"
   
   # Ä°Ã§erik Ã§ek
   curl -X POST "http://localhost:5001/api/scrape/content?limit=100"
   ```

2. **NLP Ä°ÅŸlemleri**:
   ```bash
   # Model eÄŸit
   curl -X POST "http://localhost:5001/api/nlp/train"
   
   # SÄ±nÄ±flandÄ±r
   curl -X POST "http://localhost:5001/api/nlp/classify/batch?limit=500"
   ```

3. **Veri GÃ¶rÃ¼ntÃ¼leme**:
   - Frontend'i aÃ§: `http://localhost:5173`
   - Dashboard'da istatistikleri gÃ¶rÃ¼ntÃ¼le
   - Veriler sayfasÄ±nda filtrele ve sÄ±rala

## ğŸ› Bilinen Sorunlar

- Node.js v18'de Vite uyarÄ±larÄ± (Ã§alÄ±ÅŸmaya engel deÄŸil)
- BazÄ± dinamik sayfalarda iÃ§erik Ã§ekme baÅŸarÄ±sÄ±z olabilir
- BÃ¼yÃ¼k veri setlerinde sÄ±nÄ±flandÄ±rma uzun sÃ¼rebilir

## ğŸ“„ Lisans

ISC

## ğŸ‘¥ KatkÄ±da Bulunma

1. Fork edin
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. Commit edin (`git commit -m 'Add amazing feature'`)
4. Push edin (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

## ğŸ“ Ä°letiÅŸim

SorularÄ±nÄ±z iÃ§in issue aÃ§abilirsiniz.

---

**Not**: Bu proje eÄŸitim amaÃ§lÄ± geliÅŸtirilmiÅŸtir. Production kullanÄ±mÄ± iÃ§in ek gÃ¼venlik Ã¶nlemleri alÄ±nmalÄ±dÄ±r.

